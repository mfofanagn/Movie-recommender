---
title: "MobieLensMarkDown"
author: "Mamadi Fofana"
date: "january 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

For this project, we will be creating a movie recommendation system using the MovieLens dataset. The version of MovieLens included in the dslabs package generated by the GroupLens research lab. We will be creating our own recommendation system using the 10M version of the MovieLens dataset to make the computation a little easier.
We will adopt the prediction version of recommender problem which aims is to predict the rating value for a user-item combination. 
We are going to train our algorithms using the inputs in edx dataset and to predict movie ratings in the validation set. 
The train data has 9,000,055 records in 6 variables and the validate data 999,999 records for the same variables as in the train
For this project we will be focusing on regression models using RMSE to evaluate our model
We will follow below steps:
.	loading of the two datasets,
.	pre-processing data if necessary,
.	exploration and visualization of data
.	modeling approach 
.	results obtained
.	conclusion


```{r }
library(Metrics)
library(tidyverse)
library(caret)
library(tidyverse)
#summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r }
#plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

Loading training and validate dataset
```{r}
edx <- readRDS("C:/Users/mamadi.fofana/Desktop/FOAD/Harvard Data Science/HarvardX_Capstone_MovieLens/edx.rds")
validation <- readRDS("C:/Users/mamadi.fofana/Desktop/FOAD/Harvard Data Science/HarvardX_Capstone_MovieLens/validation.rds")
```
Display data structure
```{r}
glimpse(edx)
glimpse(validation)

```
Check missing data
```{r}
which(is.na(edx))
which(is.na(validation))

```
No missing data found


Data conversion
```{r}
#edx <- edx %>% mutate(timestamp = as_datetime(timestamp)
#summary(edx)

#validation <- validation %>% mutate(timestamp = as_datetime(timestamp)
#summary(validation)

```

Data Exploration 
```{r}
summary(edx)
summary(validation)
```


Bar chart of rating variable
```{r}
 ggplot(edx, aes(x= rating)) +
    geom_bar() +
    labs(x="rating", y="population") +
    ggtitle("Count of rating for edx dataset")

ggplot(validation, aes(x= rating)) +
    geom_bar() +
    labs(x="rating", y="population") +
    ggtitle("Count of rating for validation dataset")

```
From this graph, we noticed That
.	None zeros were given as ratings in the edx dataset
.	In general, half star ratings are less common than whole star ratings (e.g., there are fewer ratings of 3.5 than there are ratings of 3 or 4, etc.).


Statistic of movies and users
```{r}
n_distinct(edx$userId)
n_distinct(edx$movieId)
```


Distribution of rating by movieId
```{r}
 edx %>% group_by(movieId)%>% summarize(n=n()) %>%
    ggplot(aes(n)) + 
    geom_histogram(bins=40) +
    scale_x_log10() +
    labs(subtitle  ="Distribtion of number of ratings by movie", 
         x="Nb rating" , 
         y="Number of movies"
         ) 
```

We can see that some movies get more ratings than others


Distribution of average rating by movie
```{r}
edx %>% group_by(movieId)%>% summarize(avg=mean(rating)) %>%
    ggplot(aes(avg)) + 
    geom_histogram(bins=40) +
    scale_x_log10() +
    labs(subtitle  ="Distribtion of average ratings by movie", 
         x="avg rating" , 
         y="Number of movies"
         )

```


Distribution of rating by userId
```{r}
edx %>% group_by(userId)%>% summarize(n=n()) %>%
    ggplot(aes(n)) + 
    geom_histogram(bins=40) +
    scale_x_log10() +
    labs(subtitle  ="Distribtion of number of ratings by user", 
         x="Nb rating" , 
         y="Number of users"
         ) 
  
```
Disti

We can that some users are more active than others

Distribution of movies by genres

```{r}
top_genre <- edx %>% separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarize(count = n()) %>%
  arrange(desc(count)) 
wordcloud(words=top_genre$genres,freq=top_genre$count,min.freq=50,
          max.words = 30,random.order=FALSE,random.color=FALSE,
          rot.per=0.35,colors = brewer.pal(8,"Dark2"),scale=c(5,.2),
          family="plain",font=2,
          main = "Top genres ")
```




```{r}
edx %>% separate_rows(genres, sep = "\\|") %>%
	group_by(genres) %>%
	summarize(count = n()) %>%
	arrange(desc(count))
```


Movie with the greatest number of ratings
```{r}
edx %>% group_by(movieId, title) %>%
	summarize(count = n()) %>%
	arrange(desc(count))
```


10 most given ratings in order from most to least
```{r}
edx %>% group_by(rating) %>% summarize(count = n()) %>% top_n(10) %>%
	arrange(desc(count))  
```



Results 
```{r}
# avgRating get the average of all ratngs of the trainng set
avgRating <- mean(edx$rating)

# movieAVG get bias rating for each movie on the training set
movieAVG <- edx %>% 
  group_by(movieId) %>% 
  summarize(avgRatingI = mean(rating - avgRating))

#userAVG get bias rating for each user on the training set 
userAVG <- edx %>%  
  left_join(movieAVG, by='movieId') %>%
  group_by(userId) %>%
  summarize(avgRatingU = mean(rating - avgRating - avgRatingI))

#Predicted ratings on validation set
predictedRatings <- validation %>% 
  left_join(movieAVG, by='movieId') %>%
  left_join(userAVG, by='userId') %>%
  mutate(pred = avgRating + avgRatingI + avgRatingU) %>%
  .$pred

#rmse get root mean squere errors on validation test
rmse <- rmse(validation$rating,predictedRatings)
rmse


```

